# ROUGE

> 论文《ROUGE: A Package for Automatic Evaluation of Summaries》
>
> 在目前的图像描述领域，最常用的是 **ROUGE-L**，也是我们本次了解学习的重点。
>
> ROUGE 评测一般主要用在文本摘要领域，主要还是借鉴机器翻译领域的BLEU等思想，下面以文本摘要任务对ROUGE以及其变种进行介绍。

## 简要介绍

ROUGE\(Recall-Oriented Understudy for Gisting Evaluation\)的思想和机器翻译结果评测方法BLEU十分的相似，早先也应用于机器翻译领域，在后来渐渐的用到了文本摘要任务中。ROUGE与BLEU的区别可以理解为前者重点在于计算召回率，而后者注重于准确率。所谓召回率通俗来说就是把系统生成的摘要和参考摘要都切分为同等长度的一些“小块”，算系统生成的“小块”在参考摘要“小块们”中所占的比例，这些小块的长度被称为n-gram。因此ROUGE的评测种类有很多，通常用ROUGE-N中的‘N’来表示小块的长度，用下面的例子来具体说明：

举例： 系统生成摘要：爱国就要买华为手机 标准参考摘要：华为与爱国无关

表1：ROUGE-N 评测举例

| 编号 | 生成摘要（1-gram） | 参考摘要（1-gram） | 生成摘要（2-gram） | 参考摘要（2-gram） |
| :--- | :--- | :--- | :--- | :--- |
| 1 | _**爱**_ | _**华**_ | _**爱国**_ | _**华为**_ |
| 2 | _**国**_ | _**为**_ | 国就 | 为与 |
| 3 | 就 | 与 | 就要 | 与爱 |
| 4 | 要 | _**爱**_ | 要买 | _**爱国**_ |
| 5 | 买 | _**国**_ | 买华 | 国无 |
| 6 | _**华**_ | 无 | _**华为**_ | 无关 |
| 7 | _**为**_ | 关 | 为手 |  |
| 8 | 手 |  | 手机 |  |
| 9 | 机 |  |  |  |
| 数量 | 9 | 7 | 8 | 6 |

则上述举例中，Rouge分数计算如下： ROUGE-1\(召回率\)= 4 / 7 = 57 % ROUGE-2\(召回率\)= 2 / 6 = 33 %

由上述例子可以看出，ROUGE不是一个单一的评价方法，而是由几种不同的角度来说明系统生成摘要中词语的语法、连贯性等。目前，ROUGE是在自然语言文本摘要领域使用最广泛的评价标准，最常见的是使用ROUGE-1，ROUGE-2，ROUGE-3等方法，因为以当前的文本摘要技术水平，当N&gt;=4时结果已经变得很小了，浮动较大，不能合理的比较不同方法的优劣。当然，在这种思路的基础上，也很快就提出了以系统生成摘要和标准参考摘要之间的最长公共子序列的长度来进行评价，被称为ROUGE-L方法，以及基于ROUGE-L改进的ROUGE-W，还有后来使用skip-gram思路的ROUGE-S方法。这些方法各有特点，应当根据其原理，在不同的环境选取合适的评测方法。下面对这几种方法进行具体说明。

## 具体介绍

### ROUGE-N（N=1，2，3 ······）

ROUGE-N相比于其他的几种方法，实现简单，结果直观，能够很好的反映单词的序列质量。下面给出其计算公式：

$$
ROUGE-N = \frac{\sum_{S\in\{Reference\}}\sum_{gram_n\in S}Count_{match}(gram_n)}{\sum_{S\in\{Reference\}}\sum_{gram_n\in S}Count(gram_n)}
$$

式（1）中Reference表示人工标注的集合，$$Count_{match}(gram_n)$$表示同时在标准参考和系统自动生成的集合中同时出现的n-gram个数。而分母上的$$Count(gram_n)$$表示参考中的n-gram数量。 由上述公式可知，ROUGE-N无非是对于召回率思想的阐述，分子表示在系统生成和标准参考中同时出现的n-gram个数，分母表示在标准参考中含有的所有的n-gram个数。 ROUGE-1和ROUGE-2 评价方法在文本摘要任务中较为常见，前者更常用于在短文本中进行评价，后者更擅长于单个文本质量的评价，当然，对多文档进行预处理，比如去除停用词等后，也可以使用二者对多文档摘要进行评测。

### ROUGE-L

字母“L”是Longest Common Subsequence的首字母，表示最长公共子序列，一般用LCS来表示。子序列是指从一个序列中选取一个或多个元素组成新的序列，新的序列可以和原序列相同。公共子序列就是指一个序列同时是两个或多个序列的子序列，公共子序列中长度最长的称之为最长公共子序列。可以用下面的例子进行说明：

_举例：_ _序列A：我很喜欢自然语言处理，可是好难啊_ _序列B：自然语言处理好难啊，所以我不喜欢_

| 编号 | 公共子序列 | 长度 | 是否为LCS |
| :--- | :--- | :--- | :--- |
| 1 | 我 | 1 | 否 |
| 2 | 喜欢 | 2 | 否 |
| 3 | 自然语言处理 | 6 | 是 |
| 4 | 好难啊 | 3 | 否 |

在给出最长公共子序列的定义后，下面给出ROUGE－L对于单句的计算公式：

$$
R_{LCS}= \frac{LCS(X,Y)}  {m}
$$

$$
P_{LCS} = \frac{LCS(X,Y)}   {n}
$$

$$
F_{LCS} = \frac{(1+\beta^2)R_{LCS}P_{LCS}}   {R_{LCS}+\beta^2 P_{LCS}}
$$

式（2）中，我们用X、Y来分别表示标准参考摘要和系统生成摘要，其中标准参考摘要的长度设为m，系统生成摘要长度为n。我们用R来表示召回率，P表示精确率，二者之间的重合度（相似度）我们用F来表示。β为参数，在国际评比中，一般设为无穷大，因此F值一般仅由$$R_{LCS}$$来确定。 ROUGE-L方法的优点在于其不要求词语必须是连续的，只要在顺序上和原序列匹配即可，因此在某方面可以说是对于生成摘要的语序的打分。

与ROUGE-N 相比，其不用指定N为多少，而可以直接以最长公共子序列为准，因此也是一种比较常用的评价方法。对于长文本，一般对其按句子进行切分，对每个句子进行打分，然后求平均值，具体公式此处不再赘述。

注：有多个参考句子的时候，逐个比较，取最大值。

### ROUGE-W（\*）

字母‘W’是Weight Longest Common Subsequence 的首字母，其意在指出ROUGE-L中的不连续的重复词和连续的重复词按照同等权重计算摘要得分的不合理性，因为连续的重复词明显比不连续的在质量上更好，应该给予更多的权重，况且不连续的重复在很多情况下会明显改变句子的意思，例如“喜欢”对于“不喜欢”十分相似，召回率高达66.6%，但是在语义上却是完全相反。正是出于这样的考虑，提出了ROUGE－W的评价方法。

ROUGE-W与ROUGE-L表示方法相比，从原理上更加的可以体现出其对于文摘的评价考虑了更多的细节，结果上也更加的精确，更能体现系统生成摘要和参考摘要之间的相似度。

### ROUGE-S （\*）

字母‘S’是Skip-gram based Co-occurrence Statistics的首字母，其重点在于“Skip-gram”，最常见的是Skip-Bigram,即最多可以跳过两个单词进行组队，然后评价摘要的质量。例如“为人民服务”的skip-bigram为{为人，为民，为服，人民，人服，人务……}。

ROUGE-S 的优点在于其考虑了所有可能出现的词对，比上述方法更能反应句子中的次序关系，对摘要结果更加友好，体现出系统生成摘要和参考摘要之间的重合度。当然缺点也在于对于skip-gram中可跳过几个字的把握，如果太多，则意味着会产生很多没有意义的人为词对。当S=0时，ROUGE-S0与ROUGE-2无差别。

